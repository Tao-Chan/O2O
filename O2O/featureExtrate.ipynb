{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame,Series\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python3\\lib\\site-packages\\ipykernel_launcher.py:273: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "d:\\python3\\lib\\site-packages\\ipykernel_launcher.py:274: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "d:\\python3\\lib\\site-packages\\ipykernel_launcher.py:275: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "d:\\python3\\lib\\site-packages\\ipykernel_launcher.py:276: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "d:\\python3\\lib\\site-packages\\ipykernel_launcher.py:277: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "d:\\python3\\lib\\site-packages\\ipykernel_launcher.py:278: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112803, 51)\n",
      "(131770, 12)\n",
      "(257126, 52)\n",
      "(131770, 12)\n",
      "(130957, 52)\n",
      "(130957, 55)\n"
     ]
    }
   ],
   "source": [
    "'''dataset split:\n",
    "                      (date_received)                              \n",
    "           dateset3: 20160701~20160731 (113640),features3 from 20160315~20160630  (off_test)\n",
    "           dateset2: 20160515~20160615 (258446),features2 from 20160201~20160514  \n",
    "           dateset1: 20160414~20160514 (138303),features1 from 20160101~20160413  \n",
    "1.merchant related: \n",
    "      sales_use_coupon. total_coupon\n",
    "      transfer_rate = sales_use_coupon/total_coupon.\n",
    "      merchant_avg_distance,merchant_min_distance,merchant_max_distance of those use coupon \n",
    "      total_sales.  coupon_rate = sales_use_coupon/total_sales.  \n",
    "       \n",
    "2.coupon related: \n",
    "      discount_rate. discount_man. discount_jian. is_man_jian\n",
    "      day_of_week,day_of_month. (date_received)\n",
    "      \n",
    "3.user related: \n",
    "      distance. \n",
    "      user_avg_distance, user_min_distance,user_max_distance. \n",
    "      buy_use_coupon. buy_total. coupon_received.\n",
    "      buy_use_coupon/coupon_received. \n",
    "      avg_diff_date_datereceived. min_diff_date_datereceived. max_diff_date_datereceived.  \n",
    "      count_merchant.  \n",
    "4.user_merchant:\n",
    "      times_user_buy_merchant_before.\n",
    "     \n",
    "5. other feature:\n",
    "      this_month_user_receive_all_coupon_count\n",
    "      this_month_user_receive_same_coupon_count\n",
    "      this_month_user_receive_same_coupon_lastone\n",
    "      this_month_user_receive_same_coupon_firstone\n",
    "      this_day_user_receive_all_coupon_count\n",
    "      this_day_user_receive_same_coupon_count\n",
    "      day_gap_before, day_gap_after  (receive the same coupon)\n",
    "'''\n",
    "off_train = pd.read_csv(r'C:\\Users\\taochan\\Desktop\\X-code\\X-data\\ccf_offline_stage1_train.csv')\n",
    "off_test = pd.read_csv(r'C:\\Users\\taochan\\Desktop\\X-code\\X-data\\ccf_offline_stage1_test_revised.csv')\n",
    "on_train = pd.read_csv(r'C:\\Users\\taochan\\Desktop\\X-code\\X-data\\ccf_online_stage1_train.csv')\n",
    "dataset3 = off_test\n",
    "feature3 = off_train[((off_train.Date>='20160315')&(off_train.Date<='20160630'))|((off_train.Date=='null')&(off_train.Date_received>='20160315')&(off_train.Date_received<='20160630'))]\n",
    "dataset2 = off_train[(off_train.Date_received>='20160515')&(off_train.Date_received<='20160615')]\n",
    "feature2 = off_train[((off_train.Date>='20160201')&(off_train.Date<='20160514'))|((off_train.Date=='null')&(off_train.Date_received>='20160201')&(off_train.Date_received<='20160514'))]\n",
    "dataset1 = off_train[(off_train.Date_received>='20160414')&(off_train.Date_received<'20160514')]\n",
    "feature1 = off_train[((off_train.Date>='20160101')&(off_train.Date<='20160413'))|((off_train.Date=='null')&(off_train.Date_received>='20160101')&(off_train.Date_received<='20160413'))]\n",
    "#每个用户收到的所有优惠券数\n",
    "#for dataset3\n",
    "# t = dataset3[['User_id']]\n",
    "# t.insert(1,'this_month_users_receive_all_coupon_count',1)\n",
    "# #t['this_month_users_receive_all_coupon_count'] = 1\n",
    "# t = t.groupby('User_id').agg('sum').reset_index()\n",
    "\n",
    "# #用户这个月收到的相同优惠券数\n",
    "# t1 = dataset3[['User_id','Coupon_id']]\n",
    "# t1.insert(1,'this_month_user_receive_same_coupon_count',1)\n",
    "# #t1['this_month_user_receive_same_coupon_count'] = 1\n",
    "# t1 = t1.groupby(['User_id','Coupon_id']).agg('sum').reset_index()\n",
    "\n",
    "# #用户最早和最迟领取优惠券时间\n",
    "# t2 = dataset3[['User_id','Coupon_id','Date_received']]\n",
    "# t2.Date_received = t2.Date_received.astype('str', copy = True)\n",
    "# t2 = t2.groupby(['User_id','Coupon_id'])['Date_received'].apply(lambda x:':'.join(x)).reset_index()\n",
    "# t2['receive_number'] = t2.Date_received.apply(lambda x :len(x.split(':')))\n",
    "# t2 = t2[t2.receive_number>1]\n",
    "# t2['max_date_received'] = t2.Date_received.apply(lambda x :max([int(d) for d in x.split(':')]))\n",
    "# t2['min_date_received'] = t2.Date_received.apply(lambda x :min([int(d) for d in x.split(':')]))\n",
    "# t2 = t2[['User_id','Coupon_id','max_date_received','min_date_received']]\n",
    "\n",
    "# #用户领取同一种优惠券最早和最迟时间\n",
    "# t3 = dataset3[['User_id','Coupon_id','Date_received']]\n",
    "# t3 = pd.merge(t3,t2,on=['User_id','Coupon_id'],how='right')\n",
    "# t3['this_month_user_received_same_coupon_lastone'] = t3.max_date_received - t3.Date_received\n",
    "# t3['this_month_user_received_same_coupon_firstone'] = t3.Date_received - t3.min_date_received\n",
    "# def isfirstorlast(x):\n",
    "#     if x ==0:\n",
    "#         return 1\n",
    "#     elif x>0:\n",
    "#         return 0\n",
    "# #     else:\n",
    "# #         return -1\n",
    "# t3.this_month_user_received_same_coupon_firstone = t3.this_month_user_received_same_coupon_firstone.apply(isfirstorlast)\n",
    "# t3.this_month_user_received_same_coupon_lastone = t3.this_month_user_received_same_coupon_lastone.apply(isfirstorlast)\n",
    "# t3 = t3[['User_id','Coupon_id','Date_received','this_month_user_received_same_coupon_firstone','this_month_user_received_same_coupon_lastone']]\n",
    "# #某天用户领取的所有优惠券数目\n",
    "# t4 = dataset3[['User_id','Date_received']]\n",
    "# t4.insert(1,'this_day_user_received_all_coupon_count',1)\n",
    "# #t4['this_day_user_received_all_coupon_count'] = 1\n",
    "# t4 = t4.groupby(['User_id','Date_received']).agg('sum').reset_index()\n",
    "\n",
    "# #用户某天领取相同优惠券数目\n",
    "# t5 = dataset3[['User_id','Coupon_id','Date_received']]\n",
    "# t5.insert(1,'this_day_user_received_same_coupon_count',1)\n",
    "# #t5['this_day_user_received_same_coupon_count'] = 1\n",
    "# t5 = t5.groupby(['User_id','Date_received']).agg('sum').reset_index()\n",
    "\n",
    "# #用户领取同一种优惠券的所有时间\n",
    "# t6 = dataset3[['User_id','Coupon_id','Date_received']]\n",
    "# t6.Date_received = t6.Date_received.astype('str')\n",
    "# t6 = t6.groupby(['User_id','Coupon_id'])['Date_received'].apply(lambda x:':'.join(x)).reset_index()\n",
    "# t6.rename(columns = {'Date_received':'dates'},inplace=True)\n",
    "# def get_day_gap_before(s):\n",
    "#     date_received,dates = s.split('-')\n",
    "#     dates = dates.split(':')\n",
    "#     gaps = []\n",
    "#     for d in dates:\n",
    "#         this_gap = (date(int(date_received[0:4]),int(date_received[4:6]),int(date_received[6:8])) - date(int(d[0:4]),int(d[4:6]),int(d[6:8]))).days\n",
    "#         if this_gap>0:\n",
    "#             gaps.append(this_gap)\n",
    "#     if len(gaps) ==0:\n",
    "#         return -1\n",
    "#     else:\n",
    "#         return min(gaps)\n",
    "        \n",
    "\n",
    "# def get_day_gap_after(s):\n",
    "#     date_received,dates = s.split('-')\n",
    "#     dates = dates.split(':')\n",
    "#     gaps = []\n",
    "#     for d in dates:\n",
    "#         this_gap = (date(int(d[0:4]),int(d[4:6]),int(d[6:8])) - date(int(date_received[0:4]),int(date_received[4:6]),int(date_received[6:8]))).days\n",
    "#         if this_gap > 0:\n",
    "#             gaps.append(this_gap)\n",
    "#     if len(gaps) == 0:\n",
    "#         return -1\n",
    "#     else:\n",
    "#         return min(gaps)\n",
    "\n",
    "# #用户领取某种优惠券和它上次/下次领取此种优惠券的时间间隔\n",
    "# t7 = dataset3[['User_id','Coupon_id','Date_received']]\n",
    "# t7 = pd.merge(t7,t6,on=['User_id','Coupon_id'],how = 'left')\n",
    "# t7['date_received_date'] = t7.Date_received.astype('str') + '-' + t7.dates\n",
    "# t7['day_gap_before'] = t7.date_received_date.apply(get_day_gap_before)\n",
    "# t7['day_gap_after'] = t7.date_received_date.apply(get_day_gap_after)\n",
    "# t7 = t7[['User_id','Coupon_id','Date_received','day_gap_before','day_gap_after']]\n",
    "# # t7.insert(1,'date_received_date',(t7.Date_received.astype('str') + '-' + t7.dates)\n",
    "# # t7.insert(1,'day_gap_before',t7.date_received_date.apply(get_day_gap_before)) \n",
    "# # t7.insert(1,'gay_gap_after',t7.date_received_date.apply(get_day_gap_after))\n",
    "\n",
    "\n",
    "# other_feature3 = pd.merge(t1,t,on = 'User_id')\n",
    "# #other_feature3 = pd.merge(other_feature3,t2,on = ['User_id','Coupon_id'])\n",
    "# other_feature3 = pd.merge(other_feature3,t3,on = ['User_id','Coupon_id'])\n",
    "# other_feature3 = pd.merge(other_feature3,t4,on = ['User_id','Date_received'])\n",
    "# other_feature3  = pd.merge(other_feature3,t5,on = ['User_id','Date_received','Coupon_id'])\n",
    "# #other_feature3 = pd.merge(other_feature3, t6, on = ['User_id','Coupon_id'])\n",
    "# other_feature3 = pd.merge(other_feature3, t7, on=['User_id','Coupon_id','Date_received'])\n",
    "# other_feature3.to_csv(r'C:\\Users\\taochan\\Desktop\\X-code\\X-data\\ExtractFeature\\other_features.csv',index=None)\n",
    "# print(other_feature3.shape)\n",
    "\n",
    "#other_feature\n",
    "# def isfirstorlast(x):\n",
    "#     if x ==0:\n",
    "#         return 1\n",
    "#     elif x>0:\n",
    "#         return 0\n",
    "#     else:\n",
    "#         return -1\n",
    "# def get_day_gap_before(s):\n",
    "#     date_received,dates = s.split('-')\n",
    "#     dates = dates.split(':')\n",
    "#     gaps = []\n",
    "#     for d in dates:\n",
    "#         this_gap = (date(int(date_received[0:4]),int(date_received[4:6]),int(date_received[6:8])) - date(int(d[0:4]),int(d[4:6]),int(d[6:8]))).days\n",
    "#         if this_gap>0:\n",
    "#             gaps.append(this_gap)\n",
    "#     if len(gaps) ==0:\n",
    "#         return -1\n",
    "#     else:\n",
    "#         return min(gaps)\n",
    "        \n",
    "\n",
    "# def get_day_gap_after(s):\n",
    "#     date_received,dates = s.split('-')\n",
    "#     dates = dates.split(':')\n",
    "#     gaps = []\n",
    "#     for d in dates:\n",
    "#         this_gap = (date(int(d[0:4]),int(d[4:6]),int(d[6:8])) - date(int(date_received[0:4]),int(date_received[4:6]),int(date_received[6:8]))).days\n",
    "#         if this_gap > 0:\n",
    "#             gaps.append(this_gap)\n",
    "#     if len(gaps) == 0:\n",
    "#         return -1\n",
    "#     else:\n",
    "#         return min(gaps)\n",
    "# def other_feature_get(dataset):\n",
    "#     t1 = dataset[['User_id','Coupon_id']]\n",
    "#     t1.insert(1,'this_month_user_receive_same_coupon_count',1)\n",
    "#     t1 = t1.groupby(['User_id','Coupon_id']).agg('sum').reset_index()\n",
    "#     #用户最早和最迟领取优惠券时间\n",
    "#     t2 = dataset[['User_id','Coupon_id','Date_received']]\n",
    "#     t2.Date_received = t2.Date_received.astype('str', copy = True)\n",
    "#     t2 = t2.groupby(['User_id','Coupon_id'])['Date_received'].apply(lambda x:':'.join(x)).reset_index()\n",
    "#     t2['receive_number'] = t2.Date_received.apply(lambda x :len(x.split(':')))\n",
    "#     t2 = t2[t2.receive_number>1]\n",
    "#     t2['max_date_received'] = t2.Date_received.apply(lambda x :max([int(d) for d in x.split(':')]))\n",
    "#     t2['min_date_received'] = t2.Date_received.apply(lambda x :min([int(d) for d in x.split(':')]))\n",
    "#     t2 = t2[['User_id','Coupon_id','max_date_received','min_date_received']]\n",
    "# #用户领取同一种优惠券最早和最迟时间\n",
    "#     t3 = dataset[['User_id','Coupon_id','Date_received']]\n",
    "#     t3 = pd.merge(t3,t2,on=['User_id','Coupon_id'],how='right')\n",
    "#     t3['this_month_user_received_same_coupon_lastone'] = t3.max_date_received - t3.Date_received.astype('int')\n",
    "#     t3['this_month_user_received_same_coupon_firstone'] = t3.Date_received.astype('int') - t3.min_date_received\n",
    "#     t3.this_month_user_received_same_coupon_firstone = t3.this_month_user_received_same_coupon_firstone.apply(isfirstorlast)\n",
    "#     t3.this_month_user_received_same_coupon_lastone = t3.this_month_user_received_same_coupon_lastone.apply(isfirstorlast)\n",
    "#     t3 = t3[['User_id','Coupon_id','Date_received','this_month_user_received_same_coupon_firstone','this_month_user_received_same_coupon_lastone']]\n",
    "#     #某天用户领取的所有优惠券数目\n",
    "#     t4 = dataset[['User_id','Date_received']]\n",
    "#     t4.insert(1,'this_day_user_received_all_coupon_count',1)\n",
    "#     #t4['this_day_user_received_all_coupon_count'] = 1\n",
    "#     t4 = t4.groupby(['User_id','Date_received']).agg('sum').reset_index()\n",
    "#     #用户某天领取相同优惠券数目\n",
    "#     t5 = dataset[['User_id','Coupon_id','Date_received']]\n",
    "#     t5.insert(1,'this_day_user_received_same_coupon_count',1)\n",
    "#     #t5['this_day_user_received_same_coupon_count'] = 1\n",
    "#     t5 = t5.groupby(['User_id','Coupon_id','Date_received']).agg('sum').reset_index()\n",
    "#     #用户领取同一种优惠券的所有时间\n",
    "#     t6 = dataset[['User_id','Coupon_id','Date_received']]\n",
    "#     t6.Date_received = t6.Date_received.astype('str')\n",
    "#     t6 = t6.groupby(['User_id','Coupon_id'])['Date_received'].apply(lambda x:':'.join(x)).reset_index()\n",
    "#     t6.rename(columns = {'Date_received':'dates'},inplace=True)\n",
    "\n",
    "#     #用户领取某种优惠券和它上次/下次领取此种优惠券的时间间隔\n",
    "#     t7 = dataset[['User_id','Coupon_id','Date_received']]\n",
    "#     t7 = pd.merge(t7,t6,on=['User_id','Coupon_id'],how = 'left')\n",
    "#     t7['date_received_date'] = t7.Date_received.astype('str') + '-' + t7.dates\n",
    "#     t7['day_gap_before'] = t7.date_received_date.apply(get_day_gap_before)\n",
    "#     t7['day_gap_after'] = t7.date_received_date.apply(get_day_gap_after)\n",
    "#     t7 = t7[['User_id','Coupon_id','Date_received','day_gap_before','day_gap_after']]\n",
    "#     # t7.insert(1,'date_received_date',(t7.Date_received.astype('str') + '-' + t7.dates)\n",
    "#     # t7.insert(1,'day_gap_before',t7.date_received_date.apply(get_day_gap_before)) \n",
    "#     # t7.insert(1,'gay_gap_after',t7.date_received_date.apply(get_day_gap_after))\n",
    "#     other_feature = pd.merge(t1,t,on = 'User_id')\n",
    "#     #other_feature = pd.merge(other_feature,t2,on = ['User_id','Coupon_id'])\n",
    "#     other_feature = pd.merge(other_feature,t3,on = ['User_id','Coupon_id'])\n",
    "#     other_feature = pd.merge(other_feature,t4,on = ['User_id','Date_received'])\n",
    "#     other_feature  = pd.merge(other_feature,t5,on = ['User_id','Coupon_id','Date_received'])\n",
    "#     #other_feature3 = pd.merge(other_feature, t6, on = ['User_id','Coupon_id'])\n",
    "#     other_feature = pd.merge(other_feature, t7, on=['User_id','Coupon_id','Date_received'])\n",
    "#     #print(other_feature.shape)\n",
    "#     return other_feature\n",
    "# other_feature3 = other_feature_get(dataset3)\n",
    "# other_feature2 = other_feature_get(dataset2)\n",
    "# other_feature1 = other_feature_get(dataset1)\n",
    "# print(other_feature3.shape,other_feature2.shape,other_feature1.shape)\n",
    "# other_feature3.to_csv(r'C:\\Users\\taochan\\Desktop\\X-code\\X-data\\ExtractFeature\\other_feature3.csv',index=None)\n",
    "# other_feature2.to_csv(r'C:\\Users\\taochan\\Desktop\\X-code\\X-data\\ExtractFeature\\other_feature2.csv',index=None)\n",
    "# other_feature1.to_csv(r'C:\\Users\\taochan\\Desktop\\X-code\\X-data\\ExtractFeature\\other_feature1.csv',index=None)\n",
    "\n",
    "\n",
    "#coupon_related_feature\n",
    "def cal_discount_rate(s):\n",
    "    s = s.split(':')\n",
    "    if len(s) == 1:\n",
    "        return float(s[0])\n",
    "    else:\n",
    "        return 1-float(s[1])/float(s[0])\n",
    "def get_discount_man(s):\n",
    "    s = s.split(':')\n",
    "    if len(s) == 1:\n",
    "        return 'null'\n",
    "    else:\n",
    "        return int(s[0])\n",
    "def get_discount_jian(s):\n",
    "    s = s.split(':')\n",
    "    if len(s) ==1:\n",
    "        return 'null'\n",
    "    else:\n",
    "        return int(s[1])\n",
    "def is_man_jian(s):\n",
    "    s = s.split(':')\n",
    "    if len(s) ==1:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "def get_coupon_related_feature(dataset,year,month,day):\n",
    "    dataset['day_of_week'] = dataset.Date_received.astype('str').apply(lambda x : date(int(x[0:4]),int(x[4:6]),int(x[6:8])).weekday() + 1)\n",
    "    dataset['day_of_month'] = dataset.Date_received.astype('str').apply(lambda x : x[6:8])\n",
    "    dataset['day_distance'] = dataset.Date_received.astype('str').apply(lambda x : (date(int(x[0:4]),int(x[4:6]),int(x[6:8])) - date(year,month,day)).days)\n",
    "    dataset['discount_man'] = dataset.Discount_rate.apply(get_discount_man)\n",
    "    dataset['discount_jian'] = dataset.Discount_rate.apply(get_discount_jian)\n",
    "    dataset['Discount_rate'] = dataset.Discount_rate.apply(cal_discount_rate)\n",
    "    d = dataset[['Coupon_id']]\n",
    "    d.insert(1,'coupon_count',1)\n",
    "    d = d.groupby('Coupon_id').agg('sum').reset_index()\n",
    "    dataset = pd.merge(dataset,d,on='Coupon_id',how ='left')\n",
    "    return dataset\n",
    "coupon_feature3 = get_coupon_related_feature(dataset3,2016,6,30)\n",
    "coupon_feature2 = get_coupon_related_feature(dataset2,2016,5,14)\n",
    "coupon_feature1 = get_coupon_related_feature(dataset1,2016,4,13)\n",
    "coupon_feature3.to_csv(r'C:\\Users\\taochan\\Desktop\\X-code\\X-data\\ExtractFeature\\coupon_feature3.csv',index=None)\n",
    "coupon_feature2.to_csv(r'C:\\Users\\taochan\\Desktop\\X-code\\X-data\\ExtractFeature\\coupon_feature2.csv',index=None)\n",
    "coupon_feature1.to_csv(r'C:\\Users\\taochan\\Desktop\\X-code\\X-data\\ExtractFeature\\coupon_feature1.csv',index=None)\n",
    "\n",
    "#merchant_related_feature\n",
    "# def get_merchant_feature(dataset):\n",
    "#     merchant = dataset[['Merchant_id','Coupon_id','Distance','Date_received','Date']]\n",
    "#     t = merchant[['Merchant_id']]\n",
    "#     t.drop_duplicates(inplace=True)\n",
    "\n",
    "#     t1 = merchant[merchant['Date']!='null'][['Merchant_id']]\n",
    "#     t1.insert(1,'total_sale',1)\n",
    "#     t1 = t1.groupby('Merchant_id').agg('sum').reset_index()\n",
    "    \n",
    "#     t2 = merchant[(merchant['Date']!='null')&(merchant['Coupon_id']!='null')][['Merchant_id']]\n",
    "#     t2.insert(1,'sale_use_coupon',1)\n",
    "#     t2 = t2.groupby('Merchant_id').agg('sum').reset_index()\n",
    "\n",
    "#     t3 = merchant[merchant['Coupon_id']!='null'][['Merchant_id']]\n",
    "#     t3.insert(1,'total_coupon',1)\n",
    "#     t3 = t3.groupby('Merchant_id').agg('sum').reset_index()\n",
    "    \n",
    "#     t4 = merchant[(merchant['Coupon_id']!='null')&(merchant['Date']!='null')][['Merchant_id','Distance']]\n",
    "#     t4.replace('null',-1,inplace = True)\n",
    "#     t4.Distance = t4.Distance.astype('int')\n",
    "#     t4.replace(-1,np.nan,inplace=True)\n",
    "    \n",
    "#     t5 = t4.groupby('Merchant_id').agg('sum').reset_index()\n",
    "#     t5.rename(columns = {'Distance':'merchant_min_distance'},inplace = True)\n",
    "    \n",
    "#     t6 = t4.groupby('Merchant_id').agg('max').reset_index()\n",
    "#     t6.rename(columns = {'Distance':'merchant_max_distance'},inplace=True)\n",
    "    \n",
    "#     t7 = t4.groupby('Merchant_id').agg('mean').reset_index()\n",
    "#     t7.rename(columns = {'Distance':'merchant_mean_distance'},inplace = True)\n",
    "    \n",
    "#     t8 = t4.groupby('Merchant_id').agg('median').reset_index()\n",
    "#     t8.rename(columns = {'Distance':'merchant_median_distance'},inplace = True)\n",
    "#     merchant_feature = pd.merge(t,t1,on='Merchant_id')\n",
    "#     merchant_feature = pd.merge(merchant_feature,t2,on='Merchant_id')\n",
    "#     merchant_feature = pd.merge(merchant_feature,t3,on='Merchant_id',how='left')\n",
    "#     #merchant_feature = pd.merge(merchant_feature,t4,on='Merchant_id',how='left')\n",
    "#     merchant_feature = pd.merge(merchant_feature,t5,on='Merchant_id',how='left')\n",
    "#     merchant_feature = pd.merge(merchant_feature,t6,on='Merchant_id',how='left')\n",
    "#     merchant_feature = pd.merge(merchant_feature,t7,on='Merchant_id',how='left')\n",
    "#     merchant_feature = pd.merge(merchant_feature,t8,on='Merchant_id',how='left')\n",
    "#     merchant_feature.sale_use_coupon = merchant_feature.sale_use_coupon.fillna(0)\n",
    "#     merchant_feature['merchant_coupon_transfer_rate'] = merchant_feature.sale_use_coupon.astype('float')/merchant_feature.total_coupon.astype('float')\n",
    "#     merchant_feature['coupon_rate'] = merchant_feature.sale_use_coupon.astype('float')/merchant_feature.total_sale.astype('float')\n",
    "#     merchant_feature.total_coupon = merchant_feature.total_coupon.fillna(0)\n",
    "\n",
    "#     return merchant_feature\n",
    "# merchant_related_feature3 = get_merchant_feature(feature3)\n",
    "# merchant_related_feature2 = get_merchant_feature(feature2)\n",
    "# merchant_related_feature1 = get_merchant_feature(feature1)\n",
    "# merchant_related_feature3.to_csv(r'C:\\Users\\taochan\\Desktop\\X-code\\X-data\\ExtractFeature\\merchant_feature3.csv',index=None)\n",
    "# merchant_related_feature2.to_csv(r'C:\\Users\\taochan\\Desktop\\X-code\\X-data\\ExtractFeature\\merchant_feature2.csv',index=None)\n",
    "# merchant_related_feature1.to_csv(r'C:\\Users\\taochan\\Desktop\\X-code\\X-data\\ExtractFeature\\merchant_feature1.csv',index=None)\n",
    "\n",
    "\n",
    "#user_related\n",
    "# def get_user_date_datereceived_gap(s):\n",
    "#     s = s.split(':')\n",
    "#     return (date(int(s[0][0:4]),int(s[0][4:6]),int(s[0][6:8])) - date(int(s[1][0:4]),int(s[1][4:6]),int(s[1][6:8]))).days\n",
    "# def get_user_feature(dataset):\n",
    "#     user = dataset[['User_id','Merchant_id','Coupon_id','Discount_rate','Distance','Date_received','Date']]\n",
    "#     t = user[['User_id']]\n",
    "#     t.drop_duplicates(inplace=True)\n",
    "    \n",
    "#     t1 = user[user['Date']!='null'][['User_id','Merchant_id']]\n",
    "#     t1.drop_duplicates(inplace=True)\n",
    "#     t1.Merchant_id = 1\n",
    "#     t1 = t1.groupby('User_id').agg('sum').reset_index()\n",
    "#     t1.rename(columns={'Merchant_id':'merchant_count'},inplace=True)\n",
    "    \n",
    "#     t2 = user[(user['Date']!='null')&(user['Coupon_id']!='null')][['User_id','Distance']]\n",
    "#     t2.replace('null',-1,inplace=True)\n",
    "#     t2.Distance = t2.Distance.astype('int')\n",
    "#     t2.replace(-1,np.nan,inplace=True)\n",
    "    \n",
    "#     t3 = t2.groupby('User_id').agg('min').reset_index()\n",
    "#     t3.rename(columns={'Distance':'user_min_diatance'},inplace=True)\n",
    "\n",
    "#     t4 = t2.groupby('User_id').agg('max').reset_index()\n",
    "#     t4.rename(columns={'Distance':'user_max_diatance'},inplace=True)\n",
    "    \n",
    "#     t5 = t2.groupby('User_id').agg('mean').reset_index()\n",
    "#     t5.rename(columns={'Distance':'user_mean_diatance'},inplace=True)\n",
    "    \n",
    "#     t6 = t2.groupby('User_id').agg('median').reset_index()\n",
    "#     t6.rename(columns={'Distance':'user_median_diatance'},inplace=True)\n",
    "    \n",
    "#     t7 = user[(user['Date']!='null')&(user['Coupon_id']!='null')][['User_id']]\n",
    "#     t7.insert(1,'buy_use_coupon',1)\n",
    "#     t7 = t7.groupby('User_id').agg('sum').reset_index()\n",
    "    \n",
    "#     t8 = user[user['Date']!='null'][['User_id']]\n",
    "#     t8.insert(1,'buy_total',1)\n",
    "#     t8 = t8.groupby('User_id').agg('sum').reset_index()\n",
    "    \n",
    "#     t9 = user[user['Coupon_id']!='null'][['User_id']]\n",
    "#     t9.insert(1,'coupon_received',1)\n",
    "#     t9 = t9.groupby('User_id').agg('sum').reset_index()\n",
    "    \n",
    "#     t10 = user[(user['Date']!='null')&(user['Date_received']!='null')][['User_id','Date_received','Date']]\n",
    "#     t10['user_date_datereceived_gap'] = t10.Date+':'+t10.Date_received\n",
    "#     t10.user_date_datereceived_gap = t10.user_date_datereceived_gap.apply(get_user_date_datereceived_gap)\n",
    "#     t10 = t10[['User_id','user_date_datereceived_gap']]\n",
    "    \n",
    "#     t11 = t10.groupby('User_id').agg('max').reset_index()\n",
    "#     t11.rename(columns={'user_date_datereceived_gap':'max_user_date_datereceived_gap'},inplace=True)\n",
    "#     t12 = t10.groupby('User_id').agg('min').reset_index()\n",
    "#     t12.rename(columns={'user_date_datereceived_gap':'min_user_date_datereceived_gap'},inplace=True)\n",
    "#     t13 = t10.groupby('User_id').agg('mean').reset_index()\n",
    "#     t13.rename(columns={'user_date_datereceived_gap':'avg_user_date_datereceived_gap'},inplace=True)\n",
    "\n",
    "#     user_feature = pd.merge(t,t1,on='User_id',how='left')\n",
    "#     user_feature = pd.merge(user_feature,t3,on='User_id',how='left')\n",
    "#     user_feature = pd.merge(user_feature,t4,on='User_id',how='left')\n",
    "#     user_feature = pd.merge(user_feature,t5,on='User_id',how='left')\n",
    "#     user_feature = pd.merge(user_feature,t6,on='User_id',how='left')\n",
    "#     user_feature = pd.merge(user_feature,t7,on='User_id',how='left')\n",
    "#     user_feature = pd.merge(user_feature,t8,on='User_id',how='left')\n",
    "#     user_feature = pd.merge(user_feature,t9,on='User_id',how='left')\n",
    "#     user_feature = pd.merge(user_feature,t11,on='User_id',how='left')\n",
    "#     user_feature = pd.merge(user_feature,t12,on='User_id',how='left')\n",
    "#     user_feature = pd.merge(user_feature,t13,on='User_id',how='left')\n",
    "    \n",
    "# #     user_feature.merchant_count = user_feature.merchant_count.fillna(0)\n",
    "# #     user_feature.buy_use_coupon = user_feature.buy_use_coupon.fillna(0)\n",
    "#     user_feature['buy_use_coupon_rate'] = user_feature.buy_use_coupon.astype('float')/user_feature.buy_total.astype('float')\n",
    "#     user_feature['user_coupon_tansfer_rate'] = user_feature.buy_use_coupon.astype('float')/user_feature.coupon_received.astype('float')\n",
    "#     user_feature = user_feature.fillna(0)\n",
    "# #     user_feature.buy_total = user_feature.buy_total.fillna(0)\n",
    "# #     user_feature.coupon_received = user_feature.coupon_received.fillna(0)\n",
    "#     return user_feature\n",
    "# user_rerlated_feature3 = get_user_feature(feature3)\n",
    "# user_rerlated_feature2 = get_user_feature(feature2)\n",
    "# user_rerlated_feature1 = get_user_feature(feature1)\n",
    "# user_rerlated_feature3.to_csv(r'C:\\Users\\taochan\\Desktop\\X-code\\X-data\\ExtractFeature\\user_feature3.csv',index=None)\n",
    "# user_rerlated_feature2.to_csv(r'C:\\Users\\taochan\\Desktop\\X-code\\X-data\\ExtractFeature\\user_feature2.csv',index=None)\n",
    "# user_rerlated_feature1.to_csv(r'C:\\Users\\taochan\\Desktop\\X-code\\X-data\\ExtractFeature\\user_feature1.csv',index=None)\n",
    "\n",
    "#user_merchant_feature\n",
    "# def get_user_merchant_feature(dataset):\n",
    "#     all_user_merchant = dataset[['User_id','Merchant_id']]\n",
    "#     all_user_merchant.drop_duplicates(inplace=True)\n",
    "    \n",
    "#     t = dataset[['User_id','Merchant_id','Date']]\n",
    "#     t = t[t['Date']!='null'][['User_id','Merchant_id']]\n",
    "#     t.insert(1,'user_merchant_buy_total',1)\n",
    "#     t = t.groupby(['User_id','Merchant_id']).agg('sum').reset_index()\n",
    "#     t.drop_duplicates(inplace=True)\n",
    "    \n",
    "#     t1 = dataset[['User_id','Merchant_id','Coupon_id']]\n",
    "#     t1 = t1[t1['Coupon_id']!='null'][['User_id','Merchant_id']]\n",
    "#     t1.insert(1,'user_merchant_received',1)\n",
    "#     t1 = t1.groupby(['User_id','Merchant_id']).agg('sum').reset_index()\n",
    "#     t1.drop_duplicates(inplace=True)\n",
    "    \n",
    "#     t2 = dataset[['User_id','Merchant_id','Date','Date_received']]\n",
    "#     t2 = t2[(t2['Date']!='null')&(t2['Date_received']!='null')][['User_id','Merchant_id']]\n",
    "#     t2.insert(1,'user_merchant_buy_use_coupon',1)\n",
    "#     t2 =t2.groupby(['User_id','Merchant_id']).agg('sum').reset_index()\n",
    "#     t2.drop_duplicates(inplace=True)\n",
    "    \n",
    "#     t3 = dataset[['User_id','Merchant_id']]\n",
    "#     t3.insert(1,'user_merchant_any',1)\n",
    "#     t3 =t3.groupby(['User_id','Merchant_id']).agg('sum').reset_index()\n",
    "#     t3.drop_duplicates(inplace=True)\n",
    "    \n",
    "#     t4 = dataset[['User_id','Merchant_id','Date','Coupon_id']]\n",
    "#     t4 = t4[(t4['Date']!='null')&(t4[\"Coupon_id\"]=='null')][['User_id','Merchant_id']]\n",
    "#     t4.insert(1,'user_merchant_buy_common',1)\n",
    "#     t4 = t4.groupby(['User_id','Merchant_id']).agg('sum').reset_index()\n",
    "#     t4.drop_duplicates(inplace=True)\n",
    "    \n",
    "#     user_merchant_feature = pd.merge(all_user_merchant,t,on=['User_id','Merchant_id'],how='left')\n",
    "#     user_merchant_feature = pd.merge(user_merchant_feature,t1,on=['User_id','Merchant_id'],how='left')\n",
    "#     user_merchant_feature = pd.merge(user_merchant_feature,t2,on=['User_id','Merchant_id'],how='left')\n",
    "#     user_merchant_feature = pd.merge(user_merchant_feature,t3,on=['User_id','Merchant_id'],how='left')\n",
    "#     user_merchant_feature = pd.merge(user_merchant_feature,t4,on=['User_id','Merchant_id'],how='left')\n",
    "#     user_merchant_feature.user_merchant_buy_use_coupon = user_merchant_feature.user_merchant_buy_use_coupon.fillna(0)\n",
    "#     user_merchant_feature.user_merchant_buy_common = user_merchant_feature.user_merchant_buy_common.fillna(0)\n",
    "#     user_merchant_feature['user_merchant_coupon_tranfer_rate'] = user_merchant_feature.user_merchant_buy_use_coupon.astype('float')/user_merchant_feature.user_merchant_received.astype('float')\n",
    "#     user_merchant_feature['user_merchant_coupon_buy_rate'] = user_merchant_feature.user_merchant_buy_use_coupon.astype('float')/user_merchant_feature.user_merchant_buy_total.astype('float')\n",
    "#     user_merchant_feature['user_merchant_buy_rate'] = user_merchant_feature.user_merchant_buy_total.astype('float')/user_merchant_feature.user_merchant_any.astype('float')\n",
    "#     user_merchant_feature['user_merchant_common_buy-rate'] = user_merchant_feature.user_merchant_buy_common.astype('float')/user_merchant_feature.user_merchant_buy_total.astype('float')\n",
    "#     user_merchant_feature = user_merchant_feature.fillna(0)\n",
    "#     return user_merchant_feature\n",
    "# user_merchant_related_feature3 = get_user_merchant_feature(feature3)\n",
    "# user_merchant_related_feature2 = get_user_merchant_feature(feature2)\n",
    "# user_merchant_related_feature1 = get_user_merchant_feature(feature1)\n",
    "# user_merchant_related_feature3.to_csv(r'C:\\Users\\taochan\\Desktop\\X-code\\X-data\\ExtractFeature\\user_merchant3.csv',index=None)\n",
    "# user_merchant_related_feature2.to_csv(r'C:\\Users\\taochan\\Desktop\\X-code\\X-data\\ExtractFeature\\user_merchant2.csv',index=None)\n",
    "# user_merchant_related_feature1.to_csv(r'C:\\Users\\taochan\\Desktop\\X-code\\X-data\\ExtractFeature\\user_merchant1.csv',index=None)\n",
    "# print(user_merchant_related_feature3.shape, user_merchant_related_feature2.shape, user_merchant_related_feature1.shape)\n",
    "\n",
    "#generate training and testing set\n",
    "def get_label(s):\n",
    "    s = s.split(':')\n",
    "    if s[0] =='null':\n",
    "        return 0\n",
    "    elif (date(int(s[0][0:4]),int(s[0][4:6]),int(s[0][6:8])) - date(int(s[1][0:4]),int(s[1][4:6]),int(s[1][6:8]))).days<=5:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "coupon3 = pd.read_csv(r'C:\\Users\\taochan\\Desktop\\X-code\\X-data\\ExtractFeature\\coupon_feature3.csv')\n",
    "merchant3 = pd.read_csv(r'C:\\Users\\taochan\\Desktop\\X-code\\X-data\\ExtractFeature\\merchant_feature3.csv')\n",
    "user3 = pd.read_csv(r'C:\\Users\\taochan\\Desktop\\X-code\\X-data\\ExtractFeature\\user_feature3.csv')\n",
    "user_merchant3 = pd.read_csv(r'C:\\Users\\taochan\\Desktop\\X-code\\X-data\\ExtractFeature\\user_merchant3.csv')\n",
    "other_feature3 = pd.read_csv(r'C:\\Users\\taochan\\Desktop\\X-code\\X-data\\ExtractFeature\\other_feature3.csv')\n",
    "dataset3 = pd.merge(coupon3,merchant3,on='Merchant_id',how='left')\n",
    "dataset3 = pd.merge(dataset3,user3,on='User_id',how='left')\n",
    "dataset3 = pd.merge(dataset3,user_merchant3,on=['User_id','Merchant_id'],how='left')\n",
    "dataset3 = pd.merge(dataset3,other_feature3,on=['User_id','Coupon_id','Date_received'],how='left')\n",
    "dataset3.drop_duplicates(inplace=True)\n",
    "print(dataset3.shape)\n",
    "dataset3['is_week_end'] = dataset3.day_of_week.apply(lambda x:1 if x in (6,7) else 0)\n",
    "weekday_dummies = pd.get_dummies(dataset3.day_of_week)\n",
    "weekday_dummies.columns = ['weekday'+str(i+1) for i in range(weekday_dummies.shape[1])]\n",
    "dataset3 = pd.concat([dataset3,weekday_dummies],axis=1)\n",
    "dataset3.drop(['Merchant_id','day_of_week','coupon_count'],axis=1,inplace=True)\n",
    "dataset3 = dataset3.replace('null',np.nan)\n",
    "print(dataset1.shape)\n",
    "\n",
    "coupon2 = pd.read_csv(r'C:\\Users\\taochan\\Desktop\\X-code\\X-data\\ExtractFeature\\coupon_feature2.csv')\n",
    "merchant2 = pd.read_csv(r'C:\\Users\\taochan\\Desktop\\X-code\\X-data\\ExtractFeature\\merchant_feature2.csv')\n",
    "user2 = pd.read_csv(r'C:\\Users\\taochan\\Desktop\\X-code\\X-data\\ExtractFeature\\user_feature2.csv')\n",
    "user_merchant2 = pd.read_csv(r'C:\\Users\\taochan\\Desktop\\X-code\\X-data\\ExtractFeature\\user_merchant2.csv')\n",
    "other_feature2 = pd.read_csv(r'C:\\Users\\taochan\\Desktop\\X-code\\X-data\\ExtractFeature\\other_feature2.csv')\n",
    "dataset2 = pd.merge(coupon2,merchant2,on='Merchant_id',how='left')\n",
    "dataset2 = pd.merge(dataset2,user2,on='User_id',how='left')\n",
    "dataset2 = pd.merge(dataset2,user_merchant2,on=['User_id','Merchant_id'],how='left')\n",
    "dataset2 = pd.merge(dataset2,other_feature2,on=['User_id','Coupon_id','Date_received'],how='left')\n",
    "dataset2.drop_duplicates(inplace=True)\n",
    "print(dataset2.shape)\n",
    "dataset2['is_week_end'] = dataset2.day_of_week.apply(lambda x:1 if x in (6,7) else 0)\n",
    "weekday_dummies = pd.get_dummies(dataset2.day_of_week)\n",
    "weekday_dummies.columns = ['weekday'+str(i+1) for i in range(weekday_dummies.shape[1])]\n",
    "dataset2 = pd.concat([dataset2,weekday_dummies],axis=1)\n",
    "dataset2['label'] = dataset2.Date.astype('str') + ':' +  dataset2.Date_received.astype('str')\n",
    "dataset2.label = dataset2.label.apply(get_label)\n",
    "dataset2.drop(['Merchant_id','day_of_week','Date','Date_received','Coupon_id','coupon_count'],axis=1,inplace=True)\n",
    "dataset2 = dataset2.replace('null',np.nan)\n",
    "print(dataset1.shape)\n",
    "\n",
    "coupon1 = pd.read_csv(r'C:\\Users\\taochan\\Desktop\\X-code\\X-data\\ExtractFeature\\coupon_feature1.csv')\n",
    "merchant1 = pd.read_csv(r'C:\\Users\\taochan\\Desktop\\X-code\\X-data\\ExtractFeature\\merchant_feature1.csv')\n",
    "user1 = pd.read_csv(r'C:\\Users\\taochan\\Desktop\\X-code\\X-data\\ExtractFeature\\user_feature1.csv')\n",
    "user_merchant1 = pd.read_csv(r'C:\\Users\\taochan\\Desktop\\X-code\\X-data\\ExtractFeature\\user_merchant1.csv')\n",
    "other_feature1 = pd.read_csv(r'C:\\Users\\taochan\\Desktop\\X-code\\X-data\\ExtractFeature\\other_feature1.csv')\n",
    "dataset1 = pd.merge(coupon1,merchant1,on='Merchant_id',how='left')\n",
    "dataset1 = pd.merge(dataset1,user1,on='User_id',how='left')\n",
    "dataset1 = pd.merge(dataset1,user_merchant1,on=['User_id','Merchant_id'],how='left')\n",
    "dataset1 = pd.merge(dataset1,other_feature1,on=['User_id','Coupon_id','Date_received'],how='left')\n",
    "dataset1.drop_duplicates(inplace=True)\n",
    "print(dataset1.shape)\n",
    "dataset1['is_week_end'] = dataset1.day_of_week.apply(lambda x:1 if x in (6,7) else 0)\n",
    "weekday_dummies = pd.get_dummies(dataset1.day_of_week)\n",
    "weekday_dummies.columns = ['weekday'+str(i+1) for i in range(weekday_dummies.shape[1])]\n",
    "dataset1 = pd.concat([dataset1,weekday_dummies],axis=1)\n",
    "dataset1['label'] = dataset1.Date.astype('str') + ':' +  dataset1.Date_received.astype('str')\n",
    "dataset1.label = dataset1.label.apply(get_label)\n",
    "dataset1.drop(['Merchant_id','day_of_week','Date','Date_received','Coupon_id','coupon_count'],axis=1,inplace=True)\n",
    "dataset1 = dataset1.replace('null',np.nan)  \n",
    "print(dataset1.shape)\n",
    "#dataset3[dataset3['day_gap_before']]\n",
    "dataset1.to_csv(r'C:\\Users\\taochan\\Desktop\\X-code\\X-data\\ExtractFeature\\dataset1.csv',index=None)\n",
    "dataset2.to_csv(r'C:\\Users\\taochan\\Desktop\\X-code\\X-data\\ExtractFeature\\dataset2.csv',index=None)\n",
    "dataset3.to_csv(r'C:\\Users\\taochan\\Desktop\\X-code\\X-data\\ExtractFeature\\dataset3.csv',index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
